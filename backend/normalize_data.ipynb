{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fefd6872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data normalized and remapped!\n",
      "\n",
      "Training data sample:\n",
      "    id  frame_count  kpt_11_x  kpt_11_y  kpt_12_x  kpt_12_y  kpt_13_x  \\\n",
      "0  101            0  0.809271  0.338811  0.862334  0.315135  0.839387   \n",
      "1  101            1  0.815820  0.348621  0.866793  0.327599  0.842920   \n",
      "2  101            2  0.817738  0.364275  0.870809  0.340094  0.844992   \n",
      "3  101            3  0.820303  0.378210  0.874671  0.351728  0.844438   \n",
      "4  101            4  0.824170  0.388362  0.880652  0.360844  0.836773   \n",
      "\n",
      "   kpt_13_y  kpt_14_x  kpt_14_y  kpt_15_x  kpt_15_y  kpt_16_x  kpt_16_y  \\\n",
      "0  0.399822  0.915538  0.369491  0.806322  0.453889  0.900765  0.414723   \n",
      "1  0.411382  0.919713  0.382588  0.810617  0.466918  0.908947  0.431616   \n",
      "2  0.426463  0.916766  0.394386  0.814951  0.483774  0.918840  0.453083   \n",
      "3  0.441129  0.926998  0.405140  0.812847  0.497191  0.923088  0.456161   \n",
      "4  0.455118  0.932521  0.412689  0.805766  0.506311  0.930001  0.461866   \n",
      "\n",
      "   kpt_23_x  kpt_23_y  kpt_24_x  kpt_24_y  \n",
      "0  0.896488  0.452383  0.932868  0.437896  \n",
      "1  0.896370  0.459178  0.933026  0.446713  \n",
      "2  0.897649  0.476661  0.936327  0.461655  \n",
      "3  0.897812  0.491934  0.937013  0.474584  \n",
      "4  0.901121  0.509175  0.943813  0.491889  \n",
      "\n",
      "Training data shape: (3449, 18)\n",
      "Columns: ['id', 'frame_count', 'kpt_11_x', 'kpt_11_y', 'kpt_12_x', 'kpt_12_y', 'kpt_13_x', 'kpt_13_y', 'kpt_14_x', 'kpt_14_y', 'kpt_15_x', 'kpt_15_y', 'kpt_16_x', 'kpt_16_y', 'kpt_23_x', 'kpt_23_y', 'kpt_24_x', 'kpt_24_y']\n",
      "\n",
      "==================================================\n",
      "Testing data sample:\n",
      "           id type_of_shot  frame_count  kpt_12_x  kpt_12_y  kpt_11_x  \\\n",
      "0  user_video        smash           21  0.522793  0.522813  0.526127   \n",
      "1  user_video        smash           22  0.522095  0.522841  0.527906   \n",
      "2  user_video        smash           23  0.522939  0.518441  0.527462   \n",
      "3  user_video        smash           24  0.524083  0.524515  0.526714   \n",
      "4  user_video        smash           25  0.521340  0.524364  0.527568   \n",
      "\n",
      "   kpt_11_y  kpt_14_x  kpt_14_y  kpt_13_x  kpt_13_y  kpt_16_x  kpt_16_y  \\\n",
      "0  0.515952  0.526208  0.554479  0.526527  0.548947  0.537674  0.579922   \n",
      "1  0.515345  0.524518  0.554635  0.527557  0.548424  0.537645  0.580251   \n",
      "2  0.511081  0.522884  0.554521  0.525389  0.539666  0.537318  0.580299   \n",
      "3  0.504069  0.519677  0.555680  0.513495  0.515500  0.537137  0.580209   \n",
      "4  0.510944  0.518640  0.554135  0.524223  0.539779  0.536368  0.579573   \n",
      "\n",
      "   kpt_15_x  kpt_15_y  kpt_24_x  kpt_24_y  kpt_23_x  kpt_23_y  \n",
      "0  0.534633  0.573548  0.512356  0.543033  0.516396  0.542291  \n",
      "1  0.535186  0.562203  0.508286  0.546387  0.512428  0.544048  \n",
      "2  0.532163  0.554762  0.507629  0.542238  0.509403  0.533518  \n",
      "3  0.516203  0.519324  0.506113  0.542308  0.505817  0.530960  \n",
      "4  0.528266  0.561856  0.504163  0.547987  0.508251  0.540944  \n",
      "\n",
      "Testing data shape: (50, 19)\n",
      "Columns: ['id', 'type_of_shot', 'frame_count', 'kpt_12_x', 'kpt_12_y', 'kpt_11_x', 'kpt_11_y', 'kpt_14_x', 'kpt_14_y', 'kpt_13_x', 'kpt_13_y', 'kpt_16_x', 'kpt_16_y', 'kpt_15_x', 'kpt_15_y', 'kpt_24_x', 'kpt_24_y', 'kpt_23_x', 'kpt_23_y']\n",
      "\n",
      "==================================================\n",
      "Training data value ranges:\n",
      "kpt_11_x: 0.0000 to 0.9704\n",
      "kpt_11_y: 0.0000 to 0.8614\n",
      "kpt_12_x: 0.1942 to 0.9909\n",
      "kpt_12_y: 0.2203 to 0.8607\n",
      "kpt_13_x: 0.0000 to 0.9938\n",
      "kpt_13_y: 0.0000 to 0.9077\n",
      "kpt_14_x: 0.0000 to 0.9961\n",
      "kpt_14_y: 0.0000 to 0.9081\n",
      "kpt_15_x: 0.0000 to 0.9859\n",
      "kpt_15_y: 0.0000 to 0.9431\n",
      "kpt_16_x: 0.0000 to 1.0000\n",
      "kpt_16_y: 0.0000 to 0.9428\n",
      "kpt_23_x: 0.2530 to 0.9727\n",
      "kpt_23_y: 0.3682 to 0.9430\n",
      "kpt_24_x: 0.2437 to 1.0000\n",
      "kpt_24_y: 0.3642 to 0.9428\n",
      "\n",
      "Testing data value ranges:\n",
      "kpt_12_x: 0.5028 to 0.5326\n",
      "kpt_12_y: 0.4850 to 0.5434\n",
      "kpt_11_x: 0.4754 to 0.5300\n",
      "kpt_11_y: 0.4961 to 0.5474\n",
      "kpt_14_x: 0.5047 to 0.5415\n",
      "kpt_14_y: 0.4443 to 0.5670\n",
      "kpt_13_x: 0.4656 to 0.5276\n",
      "kpt_13_y: 0.4909 to 0.5899\n",
      "kpt_16_x: 0.5116 to 0.5560\n",
      "kpt_16_y: 0.3995 to 0.5803\n",
      "kpt_15_x: 0.4786 to 0.5352\n",
      "kpt_15_y: 0.4701 to 0.5848\n",
      "kpt_24_x: 0.4962 to 0.5354\n",
      "kpt_24_y: 0.5422 to 0.6067\n",
      "kpt_23_x: 0.4819 to 0.5329\n",
      "kpt_23_y: 0.5310 to 0.6202\n",
      "\n",
      "==================================================\n",
      "Combined dataset saved with 3499 frames\n",
      "Training frames: 3449\n",
      "Testing frames: 50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load training data\n",
    "df_train = pd.read_csv('clean_smash_dataset.csv')\n",
    "\n",
    "# Step 1: Normalize pixel coordinates to 0-1 range for training data\n",
    "# First, we need to find the video dimensions or use the max values\n",
    "def normalize_coordinates(df):\n",
    "    \"\"\"Normalize pixel coordinates to 0-1 range\"\"\"\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # Get all x and y columns\n",
    "    x_cols = [col for col in df.columns if col.endswith('_x') and col.startswith('kpt_')]\n",
    "    y_cols = [col for col in df.columns if col.endswith('_y') and col.startswith('kpt_')]\n",
    "    \n",
    "    # Find max values for normalization (per video if needed)\n",
    "    for video_id in df['id'].unique():\n",
    "        mask = df_normalized['id'] == video_id\n",
    "        \n",
    "        # Get non-zero values to find actual frame dimensions\n",
    "        x_values = df_normalized.loc[mask, x_cols].values.flatten()\n",
    "        y_values = df_normalized.loc[mask, y_cols].values.flatten()\n",
    "        \n",
    "        x_values = x_values[x_values > 0]\n",
    "        y_values = y_values[y_values > 0]\n",
    "        \n",
    "        if len(x_values) > 0 and len(y_values) > 0:\n",
    "            max_x = x_values.max()\n",
    "            max_y = y_values.max()\n",
    "            \n",
    "            # Normalize\n",
    "            for col in x_cols:\n",
    "                df_normalized.loc[mask, col] = df_normalized.loc[mask, col] / max_x\n",
    "            for col in y_cols:\n",
    "                df_normalized.loc[mask, col] = df_normalized.loc[mask, col] / max_y\n",
    "    \n",
    "    return df_normalized\n",
    "\n",
    "# Normalize training data\n",
    "df_train_normalized = normalize_coordinates(df_train)\n",
    "\n",
    "# Step 2: Remap keypoint indices to match testing data format\n",
    "# Training uses: 5,6,7,8,9,10,11,12 -> Testing uses: 11,12,13,14,15,16,23,24\n",
    "keypoint_mapping = {\n",
    "    5: 11,   # left_shoulder\n",
    "    6: 12,   # right_shoulder\n",
    "    7: 13,   # left_elbow\n",
    "    8: 14,   # right_elbow\n",
    "    9: 15,   # left_wrist\n",
    "    10: 16,  # right_wrist\n",
    "    11: 23,  # left_hip\n",
    "    12: 24   # right_hip\n",
    "}\n",
    "\n",
    "def remap_keypoints(df, mapping):\n",
    "    \"\"\"Remap keypoint column names to match testing data format\"\"\"\n",
    "    df_remapped = pd.DataFrame()\n",
    "    \n",
    "    # Keep id and frame_count\n",
    "    df_remapped['id'] = df['id']\n",
    "    df_remapped['frame_count'] = df['frame_count']\n",
    "    \n",
    "    # Remap keypoints\n",
    "    for old_idx, new_idx in sorted(mapping.items(), key=lambda x: x[1]):\n",
    "        old_x_col = f'kpt_{old_idx}_x'\n",
    "        old_y_col = f'kpt_{old_idx}_y'\n",
    "        new_x_col = f'kpt_{new_idx}_x'\n",
    "        new_y_col = f'kpt_{new_idx}_y'\n",
    "        \n",
    "        if old_x_col in df.columns and old_y_col in df.columns:\n",
    "            df_remapped[new_x_col] = df[old_x_col]\n",
    "            df_remapped[new_y_col] = df[old_y_col]\n",
    "    \n",
    "    return df_remapped\n",
    "\n",
    "# Remap training data to match testing format\n",
    "df_train_final = remap_keypoints(df_train_normalized, keypoint_mapping)\n",
    "\n",
    "# Save normalized and remapped training data\n",
    "df_train_final.to_csv('training_data_normalized.csv', index=False)\n",
    "\n",
    "print(\"Training data normalized and remapped!\")\n",
    "print(\"\\nTraining data sample:\")\n",
    "print(df_train_final.head())\n",
    "print(f\"\\nTraining data shape: {df_train_final.shape}\")\n",
    "print(f\"Columns: {list(df_train_final.columns)}\")\n",
    "\n",
    "# Load and verify testing data format\n",
    "df_test = pd.read_csv('user_keypoints_selected.csv')\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Testing data sample:\")\n",
    "print(df_test.head())\n",
    "print(f\"\\nTesting data shape: {df_test.shape}\")\n",
    "print(f\"Columns: {list(df_test.columns)}\")\n",
    "\n",
    "# Verify value ranges\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training data value ranges:\")\n",
    "for col in df_train_final.columns:\n",
    "    if col.startswith('kpt_'):\n",
    "        print(f\"{col}: {df_train_final[col].min():.4f} to {df_train_final[col].max():.4f}\")\n",
    "\n",
    "print(\"\\nTesting data value ranges:\")\n",
    "for col in df_test.columns:\n",
    "    if col.startswith('kpt_'):\n",
    "        print(f\"{col}: {df_test[col].min():.4f} to {df_test[col].max():.4f}\")\n",
    "\n",
    "# Optional: Combine datasets for ML training\n",
    "# Make sure both have the same columns\n",
    "df_train_ml = df_train_final.copy()\n",
    "df_train_ml['type_of_shot'] = 'smash'  # Add if you have this info\n",
    "\n",
    "df_test_ml = df_test.copy()\n",
    "\n",
    "# Reorder columns to match\n",
    "common_cols = ['id', 'type_of_shot', 'frame_count'] + [col for col in df_train_ml.columns if col.startswith('kpt_')]\n",
    "df_train_ml = df_train_ml[common_cols]\n",
    "df_test_ml = df_test_ml[common_cols]\n",
    "\n",
    "# Combine\n",
    "df_combined = pd.concat([df_train_ml, df_test_ml], ignore_index=True)\n",
    "df_combined.to_csv('combined_normalized_data.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Combined dataset saved with {len(df_combined)} frames\")\n",
    "print(f\"Training frames: {len(df_train_ml)}\")\n",
    "print(f\"Testing frames: {len(df_test_ml)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itcs-3156",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
